{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNeH4y74tkIxXYqoiMNl+cu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinrz/RAFT-Motion-Blur/blob/main/RAFT_Motion_Blur.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4M5SbybncEn",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 1. Cek GPU & Install Tools\n",
        "import torch\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "print(\"⚙️ Memeriksa System...\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✅ GPU Aktif: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"❌ ERROR: GPU tidak terdeteksi. Mohon ganti Runtime Type ke T4 GPU.\")\n",
        "subprocess.run([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"], stdout=subprocess.DEVNULL)\n",
        "for f in ['input_videos', 'output_videos', 'temp_frames', 'blur_frames']:\n",
        "    if os.path.exists(f):\n",
        "        import shutil\n",
        "        shutil.rmtree(f)\n",
        "    os.makedirs(f)\n",
        "print(\"✅ System Siap!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Upload Video\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    target_path = \"input_videos/input.mp4\"\n",
        "    shutil.move(filename, target_path)\n",
        "    print(f\"✅ Video berhasil diupload: {filename} menjadi input.mp4\")\n",
        "    break"
      ],
      "metadata": {
        "id": "-S6AAUvDneYq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Settings\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision.models.optical_flow import raft_large, Raft_Large_Weights\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import subprocess\n",
        "import shutil\n",
        "from glob import glob\n",
        "import gc\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "# @markdown **Blur Direction:**\n",
        "# @markdown * `Forward`: Blur dihitung dari frame setelahnya.\n",
        "# @markdown * `Backward`: Blur dihitung dari frame sebelumnya.\n",
        "Blur_Direction = \"Backward\" #@param [\"Forward\", \"Backward\"]\n",
        "# @markdown **Tail Expansion:**\n",
        "# @markdown Feather tepi motion blur. Atur sesuai selera.\n",
        "# @markdown * `0`: Off (Tepi tajam).\n",
        "# @markdown * `30`: Tepi blur halus **Recommended**.\n",
        "Tail_Expansion = 40 #@param {type:\"slider\", min:0, max:100, step:5}\n",
        "# @markdown **Blur Strength:**\n",
        "# @markdown Panjang Blur\n",
        "# @markdown * `0.8`: Jika bingung mau atur berapa.\n",
        "Blur_Strength = 1 #@param {type:\"slider\", min:0.1, max:3.0, step:0.1}\n",
        "# @markdown **Blur Sample:**\n",
        "# @markdown Singkatnya kualitas blur. Jika diatur rendah blur akan berbayang.\n",
        "# @markdown * `128`: Atur ke tertinggi.\n",
        "Num_Samples = 128 #@param {type:\"slider\", min:16, max:128, step:8}\n",
        "# @markdown **Flow Iterations:**\n",
        "# @markdown Berapa kali setiap frame dibaca engine. Semakin tinggi semakin detail objek kecil dibaca. Dapat mempengaruhi kecepatan rendering.\n",
        "Flow_Iterations = 16 #@param {type:\"slider\", min:10, max:40, step:2}\n",
        "# @markdown **VRAM Safe Mode:**\n",
        "# @markdown Nyalakan jika sering gagal render. Kebanyakan kasus di resolusi tinggi\n",
        "VRAM_Safe_Mode = False #@param {type:\"boolean\"}\n",
        "# @markdown **Safe Mode Limit (jika VRAM safe nyala):**\n",
        "# @markdown Batas dimensi tertinggi video untuk dibaca engine. Resolusi video masih tetap asli.\n",
        "Safe_Resolution = 1280 #@param {type:\"slider\", min:960, max:1280, step:64}\n",
        "# @markdown **Consistency Check (Eksperimental):**\n",
        "# @markdown Untuk kasus jika video sudah terdapat objek screen space seperti Black bar, watermark, Overlay dll yang terus nempel dilayar.\n",
        "# @markdown * Tidak disarankan\n",
        "Consistency_Check = False #@param {type:\"boolean\"}\n",
        "# @markdown **Video Quality (CRF)**\n",
        "Video_Quality = 19 #@param {type:\"slider\", min:15, max:30, step:1}\n",
        "Internal_Resolution_Limit = Safe_Resolution if VRAM_Safe_Mode else 0\n",
        "print(f\"Getting RAFT engine...\")\n",
        "print(f\"► Direction: {Blur_Direction}\")\n",
        "print(f\"► Expansion: {Tail_Expansion}\")\n",
        "print(f\"► Blur Strength: {Blur_Strength}\")\n",
        "print(f\"► Iterations: {Flow_Iterations}\")\n",
        "print(f\"► VRAM Safe: {'ON (' + str(Internal_Resolution_Limit) + 'px)' if VRAM_Safe_Mode else 'OFF (Native)'}\")\n",
        "print(f\"► Blur Samples: {Num_Samples}\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "weights = Raft_Large_Weights.DEFAULT\n",
        "transforms = weights.transforms()\n",
        "model = raft_large(weights=weights, progress=False).to(device)\n",
        "model.eval()\n",
        "def get_grid(H, W):\n",
        "    y = torch.linspace(-1, 1, H, device=device)\n",
        "    x = torch.linspace(-1, 1, W, device=device)\n",
        "    gy, gx = torch.meshgrid(y, x, indexing='ij')\n",
        "    return torch.stack((gx, gy), dim=2).unsqueeze(0)\n",
        "def calculate_consistency(flow_fwd, flow_bwd):\n",
        "    N, C, H, W = flow_fwd.shape\n",
        "    base_grid = get_grid(H, W)\n",
        "    flow_fwd_norm = flow_fwd.permute(0, 2, 3, 1).clone()\n",
        "    flow_fwd_norm[..., 0] /= (W / 2.0)\n",
        "    flow_fwd_norm[..., 1] /= (H / 2.0)\n",
        "    grid = base_grid + flow_fwd_norm\n",
        "    warped_bwd = F.grid_sample(flow_bwd, grid, mode='bilinear', padding_mode='reflection', align_corners=True)\n",
        "    diff = flow_fwd + warped_bwd\n",
        "    magnitude = torch.norm(diff, dim=1, keepdim=True)\n",
        "    return torch.exp(-0.5 * magnitude)\n",
        "def apply_vector_blur_complex(img_tensor, flow_tensor, samples, strength, expansion, mask=None):\n",
        "    N, C, H, W = img_tensor.shape\n",
        "    base_grid = get_grid(H, W)\n",
        "    accumulated_img = torch.zeros_like(img_tensor)\n",
        "    processed_flow = flow_tensor.clone()\n",
        "    if expansion > 0:\n",
        "        k_size = int(expansion) * 2 + 1\n",
        "        processed_flow = TF.gaussian_blur(processed_flow, kernel_size=k_size, sigma=expansion)\n",
        "    flow_norm = processed_flow.permute(0, 2, 3, 1).clone()\n",
        "    flow_norm[..., 0] /= (W / 2.0)\n",
        "    flow_norm[..., 1] /= (H / 2.0)\n",
        "    for i in range(samples):\n",
        "        t = (i / (samples - 1)) - 0.5\n",
        "        offset = flow_norm * (t * strength)\n",
        "        sampling_grid = base_grid + offset\n",
        "        warped = F.grid_sample(img_tensor, sampling_grid, mode='bilinear', padding_mode='reflection', align_corners=True)\n",
        "        accumulated_img += warped\n",
        "    blurred = accumulated_img / samples\n",
        "    if mask is not None:\n",
        "        return (blurred * mask) + (img_tensor * (1 - mask))\n",
        "    else:\n",
        "        return blurred\n",
        "def pad_to_8(tensor):\n",
        "    h, w = tensor.shape[-2:]\n",
        "    new_h = ((h + 7) // 8) * 8\n",
        "    new_w = ((w + 7) // 8) * 8\n",
        "    ph = new_h - h\n",
        "    pw = new_w - w\n",
        "    if ph > 0 or pw > 0:\n",
        "        return F.pad(tensor, (0, pw, 0, ph)), h, w\n",
        "    return tensor, h, w\n",
        "input_video = \"input_videos/input.mp4\"\n",
        "output_video = \"output_videos/result.mp4\"\n",
        "temp_dir = \"temp_frames\"\n",
        "blur_dir = \"blur_frames\"\n",
        "print(\"Extracting Frames...\")\n",
        "subprocess.run(f\"ffmpeg -i {input_video} -pix_fmt rgb24 {temp_dir}/%08d.png -y -hide_banner -loglevel error\", shell=True)\n",
        "frame_files = sorted(glob(f\"{temp_dir}/*.png\"))\n",
        "print(f\"Rendering Progress...\")\n",
        "for i in tqdm(range(len(frame_files)), desc=\"Applying Motion Blur\"):\n",
        "    curr_path = frame_files[i]\n",
        "    if Blur_Direction == \"Forward\":\n",
        "        if i == len(frame_files) - 1:\n",
        "            shutil.copy(curr_path, f\"{blur_dir}/{i:08d}.png\")\n",
        "            continue\n",
        "        target_path = frame_files[i+1]\n",
        "    else:\n",
        "        if i == 0:\n",
        "            shutil.copy(curr_path, f\"{blur_dir}/{i:08d}.png\")\n",
        "            continue\n",
        "        target_path = frame_files[i-1]\n",
        "    img1_orig = cv2.cvtColor(cv2.imread(curr_path), cv2.COLOR_BGR2RGB)\n",
        "    img2_orig = cv2.cvtColor(cv2.imread(target_path), cv2.COLOR_BGR2RGB)\n",
        "    orig_h, orig_w = img1_orig.shape[:2]\n",
        "    calc_h, calc_w = orig_h, orig_w\n",
        "    scale_factor = 1.0\n",
        "    if Internal_Resolution_Limit > 0 and (orig_w > Internal_Resolution_Limit or orig_h > Internal_Resolution_Limit):\n",
        "        if orig_w >= orig_h: scale_factor = Internal_Resolution_Limit / orig_w\n",
        "        else: scale_factor = Internal_Resolution_Limit / orig_h\n",
        "        calc_w, calc_h = int(orig_w * scale_factor), int(orig_h * scale_factor)\n",
        "        img1_small = cv2.resize(img1_orig, (calc_w, calc_h), interpolation=cv2.INTER_LINEAR)\n",
        "        img2_small = cv2.resize(img2_orig, (calc_w, calc_h), interpolation=cv2.INTER_LINEAR)\n",
        "    else:\n",
        "        img1_small, img2_small = img1_orig, img2_orig\n",
        "    img1_t_full = TF.to_tensor(img1_orig).unsqueeze(0).to(device)\n",
        "    img1_t_calc = TF.to_tensor(img1_small).unsqueeze(0).to(device)\n",
        "    img2_t_calc = TF.to_tensor(img2_small).unsqueeze(0).to(device)\n",
        "    img1_batch, img2_batch = transforms(img1_t_calc, img2_t_calc)\n",
        "    img1_pad, pad_h, pad_w = pad_to_8(img1_batch)\n",
        "    img2_pad, _, _ = pad_to_8(img2_batch)\n",
        "    with torch.no_grad():\n",
        "        flow_main = model(img1_pad, img2_pad, num_flow_updates=Flow_Iterations)[-1]\n",
        "        consistency_mask = None\n",
        "        if Consistency_Check:\n",
        "            flow_reverse = model(img2_pad, img1_pad, num_flow_updates=Flow_Iterations)[-1]\n",
        "            mask_pad = calculate_consistency(flow_main, flow_reverse)\n",
        "            consistency_mask = mask_pad[:, :, :pad_h, :pad_w]\n",
        "        del img1_batch, img2_batch, img1_pad, img2_pad\n",
        "        torch.cuda.empty_cache()\n",
        "    flow_small = flow_main[:, :, :pad_h, :pad_w]\n",
        "    if scale_factor != 1.0:\n",
        "        flow_final = F.interpolate(flow_small, size=(orig_h, orig_w), mode='bilinear', align_corners=False)\n",
        "        flow_final *= (1.0 / scale_factor)\n",
        "        if consistency_mask is not None:\n",
        "            consistency_mask = F.interpolate(consistency_mask, size=(orig_h, orig_w), mode='bilinear', align_corners=False)\n",
        "    else:\n",
        "        flow_final = flow_small\n",
        "    blurred_tensor = apply_vector_blur_complex(\n",
        "        img1_t_full, flow_final, Num_Samples, Blur_Strength, Tail_Expansion, consistency_mask\n",
        "    )\n",
        "    res_img = (blurred_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
        "    res_img = cv2.cvtColor(res_img, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(f\"{blur_dir}/{i:08d}.png\", res_img)\n",
        "    del flow_main, flow_small, flow_final, blurred_tensor, img1_t_full, img1_t_calc, img2_t_calc\n",
        "    if consistency_mask is not None: del consistency_mask\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"Encoding Final Video...\")\n",
        "fps_cmd = \"ffmpeg -i input_videos/input.mp4 2>&1 | sed -n 's/.*, \\\\(.*\\\\) fp.*/\\\\1/p'\"\n",
        "orig_fps = subprocess.check_output(fps_cmd, shell=True).decode(\"utf-8\").strip()\n",
        "if not orig_fps: orig_fps = 30\n",
        "subprocess.run(f\"ffmpeg -r {orig_fps} -i {blur_dir}/%08d.png -i {input_video} -map 0:v -map 1:a -c:a copy -c:v h264_nvenc -profile:v high -level 4.1 -preset p6 -tune hq -rc constqp -qp {Video_Quality} -pix_fmt yuv420p {output_video} -y -hide_banner -loglevel error\", shell=True)\n",
        "print(f\"✅ SELESAI! Hasil tersimpan di: {output_video}\")"
      ],
      "metadata": {
        "id": "BedupShXnfdb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Download Video\n",
        "from google.colab import files\n",
        "files.download(output_video)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sGacZTZ21b4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}